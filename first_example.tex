\chapter{A First Example}
We will now look at a simple example that demonstrates all the features of
Bayesian statistics. The problem is quite simple, but we will be able to see
how we start with some probabilities at the beginning of the problem (these are
called {\it prior probabilities}), and how exactly these get updated
into after we get more information (these updated probabilities are called
{\it posterior probabilities}). To help make things clear (hopefully), we will
use a table that we will call a {\it Bayes Box} to help us calculate the
posterior probabilities.

Here we will study a simple example to see what is going on with Bayesian
statistics. Suppose that there are two balls in a bag. We know in advance
that at least one of them is black. But we're not sure whether they're both
black, or whether one is black and one is white. To keep things concise, we
should label our two competing hypotheses. We could call them whatever we want,
but I will call them \bw~and \bb. So, at the beginning of the problem, we know
that one and only one of the following statements/hypothesis is true:\\

\begin{center}
\begin{tabular}{|l|}
\hline
\bb: Both balls are black\\
\bw: One ball is black and the other is white.\\
\hline
\end{tabular}
\end{center}
We will do an experiment to help us determine which of these two hypotheses is
true. The experiment is to reach into the bag, pull out one of the balls, and
observe its colour. The result of this experiment is that the observed ball was
black.

\section{Bayes' Box}
A Bayesian analysis starts by choosing some values for the prior probabilities.
We have our two competing hypotheses \bw~and \bb, and we need to choose some
probability values to describe how sure we are that each of these is true.
For simplicity, we will assume that we don't have much of an idea which is true,
and so we will use the following prior probabilities.
\begin{eqnarray}
P(\bb) &=& 0.5\\
P(\bw) &=& 0.5.
\end{eqnarray}
This describes the fact that before we did the experiment, we were very
uncertain about which of the two hypotheses was true. Note that \bw~and \bb~are
{\it mutually exclusive}. That means that only one of
them can be true, they can't both be true (that would be contradictory). We will
often use mutually exclusive hypotheses in this course. They are also
{\it exhaustive}, which means that we assume the true solution is contained
in the set of hypothesis that we consider.

I will now present a Bayes' box, which lists all the hypotheses (in this case
two) that might be true, and the prior probabilities. There are some extra
columns which we haven't discussed yet, which will be needed in order to
figure out the posterior probabilities in the final column.
\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
{\bf Hypotheses} & {\tt prior} & {\tt likelihood} &
{\tt prior $\times$ likelihood} & {\tt posterior}\\
\hline
{\tt BB} & 0.5 &   &  & \\
{\tt BW} & 0.5 &   &  & \\
\hline
Totals: & 1 & & & \\
\hline
\end{tabular}
\end{center}
\end{table}


The data that we have seen is 

\section{Bayes' Rule}
In general, Bayes' rule looks like this:
\begin{eqnarray}
P(H|D) = \frac{P(H)P(D|H)}{P(D)}
\end{eqnarray}
Here's what all the terms mean:
\begin{itemize}
\item $P(H|D)$ is the {\bf posterior probability}. It describes how sure we are that
hypothesis $H$ is true, given that we have observed data $D$. Calculating
posterior probabilities is the main goal of Bayesian statistics!
\item $P(H)$ is the {\bf prior probability}, which describes how sure we were that
$H$ was true, before we observed the data $D$.
\item $P(D|H)$ is the {\bf likelihood}. If you were to assume that $H$ is true,
this is the probability that you would have observed data $D$.
\item $P(D)$ is the {\bf marginal likelihood}. This is the probability that you
would have observed data $D$, {\it whether $H$ is true or not}.
\end{itemize}










\section{Phone Example}
This example appeared in the 2012 final exam.


