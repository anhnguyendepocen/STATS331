\chapter{First Examples}
We will now look at a simple example that demonstrates all the features of
Bayesian statistics. The problem is quite simple, but we will be able to see
how we start with some probabilities at the beginning of the problem (these are
called {\it prior probabilities}), and how exactly these get updated
into after we get more information (these updated probabilities are called
{\it posterior probabilities}). To help make things clear (hopefully), we will
use a table that we will call a {\it Bayes Box} to help us calculate the
posterior probabilities.

Here we will study a simple example to see what is going on with Bayesian
statistics. Suppose that there are two balls in a bag. We know in advance
that at least one of them is black. But we're not sure whether they're both
black, or whether one is black and one is white. To keep things concise, we
should label our two competing hypotheses. We could call them whatever we want,
but I will call them \bw~and \bb. So, at the beginning of the problem, we know
that one and only one of the following statements/hypothesis is true:\\

\begin{center}
\begin{tabular}{|l|}
\hline
\bb: Both balls are black\\
\bw: One ball is black and the other is white.\\
\hline
\end{tabular}
\end{center}
We will do an experiment to help us determine which of these two hypotheses is
true. The experiment is to reach into the bag, pull out one of the balls, and
observe its colour. {\it The result of this experiment is that the observed
ball was black}. We will now do a Bayesian analysis of this result, to see how
it works.

\section{The Bayes' Box}
A Bayesian analysis starts by choosing some values for the prior probabilities.
We have our two competing hypotheses \bw~and \bb, and we need to choose some
probability values to describe how sure we are that each of these is true.
For simplicity, we will assume that we don't have much of an idea which is true,
and so we will use the following prior probabilities.
\begin{eqnarray}
P(\bb) &=& 0.5\\
P(\bw) &=& 0.5.
\end{eqnarray}
This describes the fact that before we did the experiment, we were very
uncertain about which of the two hypotheses was true. Note that \bw~and \bb~are
{\it mutually exclusive}. That means that only one of
them can be true, they can't both be true (that would be contradictory). We will
usually use mutually exclusive hypotheses in this course. They are also
{\it exhaustive}, which means that we assume the true solution is contained
in the set of hypothesis that we consider. We will also assume this every time.

I will now present a {\it Bayes' Box}, which lists all the hypotheses (in this
case
two) that might be true, and the prior probabilities. There are some extra
columns which we haven't discussed yet, which will be needed in order to
figure out the posterior probabilities in the final column.
\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
{\bf Hypotheses} & {\tt prior} & {\tt likelihood} &
{\tt prior $\times$ likelihood} & {\tt posterior}\\
\hline
{\tt BB} & 0.5 &   &  & \\
{\tt BW} & 0.5 &   &  & \\
\hline
Totals: & 1 & & & \\
\hline
\end{tabular}
\end{center}
\end{table}
The first column of a Bayes' Box is just the list of hypotheses we are
considering. If you need to construct a Bayes' box for a new problem, just think
about what the possible answers to the problem are, and list them in the first
column. The second column lists the prior probabilities for each of the
hypotheses.
Since we know one and only
one of the two hypotheses is true, and we want our prior probabilities to
describe a large amount of uncertainty, we shall say that there is a 50\%
probability that \bb~is true and a 50\% probability that \bw~is true.
The prior column should always sum to 1. Remember, the prior probabilities
only describe our initial uncertainty, before taking into account the
data. Hopefully the data will help by changing these probabilities to
something else!

\subsection{Likelihood}
The third column is called {\it likelihood}, and this is a really important
column. It is a quantity that will be used for calculating the posterior
probabilities. In colloquial language, likelihood is synonymous with
probability; it means the same thing. However, in statistics, likelihood is a
very
specific kind of probability. To fill in the third column of the Bayes' Box,
we need to calculate two likelihoods, so you can tell from this that the
likelihood is something that is different for each hypothesis. But what is it
exactly? Here is the answer:
\begin{framed}
{\bf The likelihood column entries are found by imagining each hypothesis
is true, and working out the probability
that you would have observed the data that you did, in fact, observe.}
\end{framed}

Here is the Bayes' Box with the likelihood column filled in. I will explain
how these numbers were calculated in more detail in the next subsection.
\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
{\bf Hypotheses} & {\tt prior} & {\tt likelihood} &
{\tt prior $\times$ likelihood} & {\tt posterior}\\
\hline
{\tt BB} & 0.5 & 1 &  & \\
{\tt BW} & 0.5 & 0.5 &  & \\
\hline
Totals: & 1 & & & \\
\hline
\end{tabular}
\end{center}
\end{table}
If you have taken STATS 210 and used the maximum likelihood method, where you
find the value of a parameter that maximises the likelihood function, that is
the same as the likelihood we use in this course! So you have a head start
in understanding this concept.

\subsection{Finding the Likelihood Values}
Let us first calculate the value of the likelihood for the \bb~hypothesis.
Remember, the data we are analysing here is that we chose one of the balls in
the bag at random, and it was black. The likelihood for the \bb~hypothesis is
therefore the probability that we would get a black ball if \bb~is true.

Imagine that \bb~is true, so both balls are black. What is the probability that
the experiment would result in a black ball? That's easy -- it's 100\%! So we
put the number 1 in the Bayes Box as the likelihood for the \bb~hypothesis.

Now imagine instead that \bw~is true. That would mean one ball is black and the
other is white. If this were the case and we did the experiment, what would be
the probability of getting the black ball in the experiment? Since one of the
two balls is black, the chance of choosing this one is 50\%. Therefore the
likelihood for the \bw~hypothesis is 0.5, so that's why I put 0.5 in the Bayes'
Box for the likelihood for \bw.

In general, the likelihood is the {\it probability of the data that you actually
got, assuming that a particular hypothesis is true}. In this example it was
fairly easy to get the likelihoods directly by asking ``if this hypothesis
were true, what would be the probability of the experiment outcome being the
black ball?''. Sometimes it's not so easy, and it can be helpful to think about
ALL possible experimental outcomes/data you might have seen -- even though
ultimately, you need to select the one that actually occurred.
Table~\ref{tab:all_data} shows an example of this process.

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
{\bf Hypotheses} & {\bf Possible Data} & {\bf Probability} \\
\hline
{\tt BB} & {\color{blue} Black Ball} & {\color{blue} 1}\\
         & White Ball & 0 \\
\hline
{\tt BW} & {\color{blue} Black Ball} & {\color{blue} 0.5} \\
         & White Ball & 0.5 \\
\hline
\end{tabular}
\caption{This table demonstrates a method for calculating the likelihood
values, by considering not just the data that actually occurred, but all
data that might have occurred. Ultimately, it is only the probability of the
data that actually occurred that matters, so this is highlighted in blue.
\label{tab:all_data}}
\end{center}
\end{table}
The fact that only the blue probabilities in Table~\ref{tab:all_data} enter the
Bayes' Box calculation is related to the {\it likelihood principle} which is
discussed in lectures.

\section{Bayes' Rule}
Bayes' rule is an equation from probability theory, shown in
Figure~\ref{fig:bayes_neon}. The various terms in Bayes' rule are all
probabilities, but notice that there are conditional probabilities in there.
For example, the left hand side of the equation is $P(A|B)$ and that means
the probability of $A$ {\bf given} $B$; that is, it's the probability of $A$
after taking into account the information $B$. In other words,
$P(A|B)$ is a posterior probability, and Bayes' rule tells us how to calculate
it from other probabilities.
\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.4]{bayes_neon.jpg}
\caption{A blue neon sign displaying Bayes' rule.
You can use it to calculate the probability of $A$ {\it given} $B$,
if you know the values of some other probabilities on the right hand side.
Image credit: Matt Buck. Obtained from Wikimedia Commons.
\label{fig:bayes_neon}}
\end{center}
\end{figure}
Bayes' rule is true for {\it any} statements $A$ and $B$. If you took the
equation in Figure~\ref{fig:bayes_neon} and replaced $A$ with
``K\={a}k\={a}p\={o} will survive beyond 2050'' and $B$ with
``I had coffee this morning'', the
resulting equation would still be true\footnote{Albeit not very interesting,
because
whether or not I had coffee doesn't tell you much about the survival prospects
of endangered New Zealand parrots.}.

It is helpful to relabel $A$ and $B$ in Bayes' rule to give a more clear
interpretation of how the equation is to be used. In this version of Bayes'
rule (which is one you should commit to memory), $A$ has been replaced by $H$,
and $B$ has been replaced by $D$. The reason for this is that you should
interpret $H$ as {\it hypothesis} and $D$ as {\it data}. Then you can interpret
Bayes' rule as telling you the probability of a hypothesis given some data --
that is, a posterior probability.
\begin{eqnarray}
P(H|D) = \frac{P(H)P(D|H)}{P(D)}
\end{eqnarray}
In Bayesian statistics, most of the terms in Bayes' rule have special names.
Some of them even have more than one name, with different scientific
communities preferring different terminology. Here is a list of the
various terms and the names we will use for them:
\begin{itemize}
\item $P(H|D)$ is the {\bf posterior probability}. It describes how certain
or confident we are that
hypothesis $H$ is true, given that we have observed data $D$. Calculating
posterior probabilities is the main goal of Bayesian statistics!
\item $P(H)$ is the {\bf prior probability}, which describes how sure we were
that $H$ was true, before we observed the data $D$.
\item $P(D|H)$ is the {\bf likelihood}. If you were to assume that $H$ is true,
this is the probability that you would have observed data $D$.
\item $P(D)$ is the {\bf marginal likelihood}. This is the probability that you
would have observed data $D$, {\it whether $H$ is true or not}.
\end{itemize}

In the above section, we did some calculations to work out the numbers in the
Bayes' Box, particularly the posterior probabilities, which are the ultimate
goal of the calculation. {\it What we were actually doing in these calculations
was applying Bayes' rule}. We actually applied Bayes' rule twice, once to
compute $P(\bb | D)$ and once to calculate $P(\bw | D)$.


\begin{center}
\begin{tabular}{|c|}
\hline
{\bf When you use a Bayes' Box to calculate posterior probabilities,}\\
{\bf you are really just applying Bayes' rule a lot of times:}\\
{\bf once for each row of the Bayes' Box.}\\
\hline
\end{tabular}
\end{center}

\section{Phone Example}
\subsection{The Question}
This example is based on Question 1 from the 2012 final exam of STATS 331. The
idea for this question was based on an example in David MacKay's wonderful book
``Information Theory, Inference and Learning Algorithms''
(available online as a free PDF download -- you're welcome to check it out, but
it is a large book and only about 20\% of it is related to this course!).

You move into a new house which has a phone
installed. You can't remember the phone number, but you suspect it
might be {\tt 555-3226} (some of you may recognise
this as being the phone number for Homer Simpson's ``Mr Plow'' business).
To test this hypothesis, you carry out an experiment
by picking up the phone and dialing {\tt 555-3226}.

If you are correct about
the phone number, you will definitely hear a busy signal because you are calling
yourself.
If you are incorrect, the probability of hearing a busy signal is $1/100$.
However, all of that is only true if you assume the phone is working -- and it
might be broken! If the phone is broken, it will always give a busy signal.

When you do the experiment, you do actually get the busy signal.
Find the posterior probability the following four hypotheses:
\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Hypothesis & Description & Prior Probability\\
\hline
$H_1$ & Phone is working and {\tt 555-3226} is correct & 0.4\\
$H_2$ & Phone is working and {\tt 555-3226} is incorrect & 0.4\\
$H_3$ & Phone is broken and {\tt 555-3226} is correct & 0.1\\
$H_4$ & Phone is broken and {\tt 555-3226} is incorrect & 0.1\\
\hline
\end{tabular}
\caption{The four hypotheses about the state of the phone and the phone
number. The prior probabilities are also given.\label{tab:phone}}
\end{center}
\end{table}

\subsection{Solution}
We will go through the solution using a Bayes' Box. The four hypotheses listed
in Table~\ref{tab:phone} are mutually exclusive and exhaustive, so we can fill
out the first two columns of a Bayes' Box right away:
\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
{\bf Hypotheses} & {\tt prior} & {\tt likelihood} &
{\tt prior $\times$ likelihood} & {\tt posterior}\\
\hline
$H_1$ & 0.4 &  &  & \\
$H_2$ & 0.4 &  &  & \\
$H_3$ & 0.1 &  &  & \\
$H_4$ & 0.1 &  &  & \\
\hline
Totals: & 1 & & & \\
\hline
\end{tabular}
\end{center}
\end{table}
The next thing we need are the likelihoods. The data was that we got the busy
signal, so we need to work out $P(\textnormal{busy signal} | H)$ for each $H$
in the problem (there are four of them).



\section{Important Equations to Remember}
Bayes' rule for a single hypothesis $H$ given data $D$:
\begin{eqnarray}
P(H|D) = \frac{P(H)P(D|H)}{P(D)}
\end{eqnarray}

Bayes' rule for a set of hypotheses (mutually exclusive, exhaustive)
$H_1, H_2, ..., H_N$, given data $D$:
\begin{eqnarray}
P(H_i|D) &=& \frac{P(H_i)P(D|H_i)}{P(D)} \\
&=& \frac{P(H_i)P(D|H_i)}{\sum_{j=1}^N P(H_j)P(D|H_j)}
\end{eqnarray}
Following the steps for making a Bayes' Box is equivalent to using this form
of Bayes' rule. The $P(H_i)$ values are the prior probability column, the
$P(D|H_i)$ values are the likelihood column, and the denominator is the
sum of the prior times likelihood column.

