\chapter{Probability}
This course will use probability theory extensively. In fact, Bayesian
Statistics is really just probability theory used for a particular purpose --
to describe uncertainty.

The two most important rules of probability are given below.

\section{The Product Rule}
The first important rule of probability is the
product rule. This tells us how to calculate the probability that any two
propositions $A$ and $B$ are {\bf both} true. The probability of $A$ {\bf and}
$B$ will be denoted $P(A, B)$. This can be calculated by first finding the
probability that $A$ is true, and then multiply by the probability that $B$ is
true {\bf given} that $A$ is true.
\begin{eqnarray}
P(A, B) &=& P(A)P(B|A)\label{product1}
\end{eqnarray}
We could also have done this the other way around: first finding the
probability that $B$ is true and then the probability that $A$ is true given
that $B$ is true:
\begin{eqnarray}
P(A, B) &=& P(B)P(A|B).\label{product2}
\end{eqnarray}

\subsection{Bayes' Rule}
Looking at Equations~\ref{product1} and~\ref{product2}, they are both equations
for the same
thing, $P(A,B)$. Therefore we can equate the right hand sides. Doing this gives
a result known as Bayes' rule:
\begin{eqnarray}
P(A|B) &=& \frac{P(A)P(B|A)}{P(B)}. \label{bayes}
\end{eqnarray}
Bayes' rule will be used extensively throughout this course. You will need to
know it and know how to use it!

\section{The Sum Rule}
The sum rule is the second important rule of probability. It is used to obtain
the probability that some proposition $A$ is true from some other
probabilities:
\begin{eqnarray}
P(A) = P(A, B) + P(A, \not B)
\end{eqnarray}

\section{Random Variables}

\subsection{Discrete Random Variables}
Probability mass function
$P(X=x) = p(x)$


\subsection{Continuous Random Variables}
Probability density function
$f(x)$


\section{Shorthand Notation}



\section{Useful Probability Distributions}

\subsection{Normal}


\subsection{Binomial}


\subsection{Beta}


\subsection{Poisson}


