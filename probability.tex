\chapter{Probability Theory}
This course will use probability theory extensively. In fact, Bayesian
Statistics is really just probability theory used for a particular purpose --
to describe uncertainty.

The two most important rules of probability are given below.

\section{The Product Rule}
The first important rule of probability is the
product rule. This tells us how to calculate the probability that any two
propositions or hypotheses $A$ and $B$ are {\bf both} true.
The probability of $P$ {\bf and}
$B$ will be denoted $P(A, B)$. This can be calculated by first finding the
probability that $A$ is true, and then multiplying by the probability that $B$
is true {\it given} that $A$ is true.
\begin{eqnarray}
P(A, B) &=& P(A)P(B|A)\label{product1}
\end{eqnarray}
We could also have done this the other way around: first finding the
probability that $B$ is true and then the probability that $A$ is true given
that $B$ is true:
\begin{eqnarray}
P(A, B) &=& P(B)P(A|B).\label{product2}
\end{eqnarray}
You may be familiar with the idea of a {\it tree diagram} from earlier
statistics courses or maybe even high school. A tree diagram is a helpful way
to work with the product rule.

\subsection{Bayes' Rule}
Looking at Equations~\ref{product1} and~\ref{product2}, they are both equations
for the same
thing, $P(A,B)$. Therefore we can equate the right hand sides. Doing this gives
a result known as Bayes' rule:
\begin{eqnarray}
P(A|B) &=& \frac{P(A)P(B|A)}{P(B)}. \label{bayes}
\end{eqnarray}
Bayes' rule will be used extensively throughout this course. You will need to
know it and know how to use it!

\section{The Sum Rule}
The sum rule is the second important rule of probability. It is used to obtain
the probability that some proposition $A$ is true from some other
probabilities:
\begin{eqnarray}
P(A) = P(A, B) + P(A, \not B)
\end{eqnarray}

\section{Random Variables}

\subsection{Discrete Random Variables}
We will also see quite a lot of random variables in this course. A discrete
random variable is just a quantity $X$ that has a countable number of possible
values.

Probability mass function
$P(X=x) = p(x)$

For example, the equation for the Poisson distribution (a useful discrete
distribution) is:
\begin{eqnarray}
P(X=x) &=& \frac{\lambda^x e^{-\lambda}}{x!}
\end{eqnarray}
for $x \in \{0, 1, 2, 3, ...\}$.

\subsection{Continuous Random Variables}
Probability density function
$f(x)$


\section{Shorthand Notation}

P

\section{Useful Probability Distributions}

\subsection{Normal}
The normal distribution (also sometimes known as the Gaussian distribution,
after Gauss) is an extremely common continuous probability distribution.
The equation for the probability density function of a standard normal
distribution is:
\begin{eqnarray}
P(x) &=& \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^2}.
\end{eqnarray}

\subsection{Binomial}


\subsection{Beta}


\subsection{Poisson}


